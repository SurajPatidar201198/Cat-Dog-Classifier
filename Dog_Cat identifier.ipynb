{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sam\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing the keras libraries and packages\n",
    "from keras.models import Sequential #its the model we are using \n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialising the CNN(classifier neural network)\n",
    "classifier=Sequential()\n",
    "#Convolution\n",
    "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu')) #here input shape is the pixels of the image i.e 64*64 and 3 is that every pixel has 3 values. and the Conv2D is used to convert the image in 2D as it is in form of 64*64*3\n",
    "#pooling\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#adding the second convolutional layer\n",
    "classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))#pools the data from 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flattening\n",
    "classifier.add(Flatten()) #SINCE WE ARE working with the 2D image which is actually the 3D image and by using flatten we are converting it to the one dimensional array\n",
    "#Full connections\n",
    "classifier.add(Dense(units=128,activation='relu')) # you can take any value at units we are taking 126(64+64) you may take 64+32 depending on the size of the data or image.\n",
    "classifier.add(Dense(units=1,activation='sigmoid'))  #we are using here units=1 because we want to know whether it is a cat or dog sigmoid is used for yes or no answers.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the CNN\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])#optimiser is a reverse propogation whixh is used to handle or manages the values of weights if there comes errors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set= train_datagen.flow_from_directory('Downloads/training_set',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale = 1./255)\n",
    "test_set=train_datagen.flow_from_directory('Downloads/test_set',target_size=(64,64),batch_size=32,class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8000/8000 [==============================] - 2550s 319ms/step - loss: 9.3451e-05 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/25\n",
      "8000/8000 [==============================] - 2515s 314ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 3/25\n",
      "8000/8000 [==============================] - 2245s 281ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 4/25\n",
      "8000/8000 [==============================] - 2187s 273ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 5/25\n",
      "8000/8000 [==============================] - 2181s 273ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 6/25\n",
      "8000/8000 [==============================] - 2173s 272ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 7/25\n",
      "8000/8000 [==============================] - 2137s 267ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 8/25\n",
      "8000/8000 [==============================] - 2119s 265ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 9/25\n",
      "8000/8000 [==============================] - 2117s 265ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 10/25\n",
      "8000/8000 [==============================] - 2118s 265ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 11/25\n",
      "8000/8000 [==============================] - 2115s 264ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 12/25\n",
      "8000/8000 [==============================] - 2116s 264ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 13/25\n",
      "8000/8000 [==============================] - 2113s 264ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 14/25\n",
      "8000/8000 [==============================] - 2112s 264ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 15/25\n",
      "8000/8000 [==============================] - 2113s 264ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 16/25\n",
      "8000/8000 [==============================] - 2250s 281ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 17/25\n",
      "8000/8000 [==============================] - 2439s 305ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 18/25\n",
      "8000/8000 [==============================] - 2334s 292ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 19/25\n",
      "8000/8000 [==============================] - 2473s 309ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 20/25\n",
      "8000/8000 [==============================] - 2290s 286ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 21/25\n",
      "8000/8000 [==============================] - 2267s 283ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 22/25\n",
      "8000/8000 [==============================] - 2241s 280ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 23/25\n",
      "8000/8000 [==============================] - 2247s 281ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 24/25\n",
      "8000/8000 [==============================] - 2260s 282ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 25/25\n",
      "8000/8000 [==============================] - 2274s 284ms/step - loss: 1.0000e-07 - acc: 1.0000 - val_loss: 16.1181 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f1ace31940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,steps_per_epoch=8000,epochs=25,validation_data=test_set,validation_steps=2000)#backpropogation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the value of the accuracy goes down and the value_accuracy goes up then there is a bias which means that the model is memorising the things it is not making that what makes a dog a dog and a cat a cat.these is the beauty of the keras.just by  the values we can know what our model is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "#making out of sample prediction\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image=image.load_img('Downloads/single_prediction/cat_or_dog_1.jpg',target_size=(64,64))\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image, axis = 0)#making the image in a single array as axis=0\n",
    "result=classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction='dog'\n",
    "else:\n",
    "    prediction='cat'\n",
    "    \n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
